{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <h1><center>CMSC 478: Introduction to Machine Learning</center></h1>\n",
    "\n",
    "<center><img src=\"img/title.jpg\" align=\"center\"/></center>\n",
    "\n",
    "\n",
    "<h3 style=\"color:blue;\"><center>Instructor: Fereydoon Vafaei</center></h3>\n",
    "\n",
    "\n",
    "<h5 style=\"color:purple;\"><center>Training Deep Neural Networks</center></h5>\n",
    "\n",
    "<center><img src=\"img/UMBC_logo.png\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Agenda</center></h1>\n",
    "\n",
    "- <b>Training Deep Neural Networks</b>\n",
    "    - Vanishing and Exploding Gradients\n",
    "    - Glorot and He initialization\n",
    "    - Dying Neurons\n",
    "    - Nonsaturating Activation Functions\n",
    "        - Leaky ReLU\n",
    "        - ELU\n",
    "        - SELU\n",
    "    - Batch Normalization\n",
    "    - Gradient Clipping\n",
    "    - Transfer Learning\n",
    "    - Unsupervised Pretraining\n",
    "    - Faster Optimizers\n",
    "    - Learning Rate Scheduling\n",
    "    - Regularization and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Vanishing and Exploding Gradients</center></h1>\n",
    "\n",
    "- During training DNNs, gradients often get smaller and smaller as the algorithm progresses down to the lower layers.\n",
    "\n",
    "\n",
    "- As a result, the Gradient Descent update leaves the lower layers’ connection weights virtually unchanged, and training never converges to a good solution. This is called the **vanishing gradients** problem.\n",
    "\n",
    "\n",
    "- In some cases, the opposite can happen: the gradients can grow bigger and bigger until layers get insanely large weight updates and the algorithm diverges. This is the **exploding gradients** problem, which surfaces in **Recurrent Neural Networks (RNN)**.\n",
    "\n",
    "\n",
    "- More generally, DNNs suffer from **unstable gradients**; different layers may learn at widely different speeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Logistic Function Saturation</center></h1>\n",
    "\n",
    "<center><img src=\"img/saturation.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Image from Ref[1]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Glorot and He Initialization</center></h1>\n",
    "\n",
    "- In their paper, Glorot and Bengio propose a way to significantly alleviate the unstable gradients problem.\n",
    "\n",
    "\n",
    "- They point out that we need the signal to flow properly in both directions: in the forward direction when making predictions, and in the reverse direction when backpropagating gradients.\n",
    "\n",
    "\n",
    "- We don’t want the signal to die out, nor do we want it to explode and saturate.\n",
    "\n",
    "\n",
    "- For the signal to flow properly, the authors argue that we need the variance of the outputs of each layer to be equal to the variance of its inputs, and we need the gradients to have equal variance before and after flowing through a layer in the reverse direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Glorot and He Initialization Equations</center></h1>\n",
    "\n",
    "- The connection weights of each layer must be initialized randomly as described in Equation 11-1, where $fan_{in}$ is the number of inputs of the layer and $fan_{out}$ is the number of neurons of the layer and \n",
    "$fan_{avg} = (fan_{in} + fan_{out})/2$.\n",
    "\n",
    "\n",
    "- This initialization strategy is called **Xavier initialization** or **Glorot initialization**, after the paper’s first author.\n",
    "\n",
    "<center><img src=\"img/glorot.png\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Initialization Summary</center></h1>\n",
    "\n",
    "- By default, Keras uses **Glorot** initialization with a uniform distribution.\n",
    "\n",
    "<center><img src=\"img/init.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Table from Ref[1]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'serialize',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Example of changing the initialization method\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "\n",
    "# Example of changing the parameters of the initialization method\n",
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Dying Neurons and Nonsaturating Activation Functions</center></h1>\n",
    "\n",
    "- The ReLU activation function is not perfect. It suffers from a problem known as the **dying ReLUs** (or dying neurons): during training, some neurons effectively “die,” meaning they stop outputting anything other than 0.\n",
    "\n",
    "\n",
    "- In some cases, you may find that half of your network’s neurons are dead, especially if you used a large learning rate.\n",
    "\n",
    "\n",
    "- A neuron dies when its weights get tweaked in such a way that the weighted sum of its inputs are negative for all instances in the training set. When this happens, it just keeps outputting zeros, and Gradient Descent does not affect it anymore because the gradient of the ReLU function is zero when its input is negative.\n",
    "\n",
    "\n",
    "- To solve this problem, you may want to use a variant of the ReLU function, such as the **leaky ReLU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, 5, -0.5, 4.2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)\n",
    "z = np.linspace(-5, 5, 200)\n",
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activation functions in keras\n",
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Equation 11-2: ELU activation function**\n",
    "\n",
    "$\n",
    "\\operatorname{ELU}_\\alpha(z) =\n",
    "\\begin{cases}\n",
    "\\alpha(\\exp(z) - 1) & \\text{if } z < 0\\\\\n",
    "z & if z \\ge 0\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, 5, -2.2, 3.2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)\n",
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>ELU Properties</center></h1>\n",
    "\n",
    "- ELU takes on negative values when z < 0, which allows the unit to have an average output closer to 0 and helps alleviate the **vanishing gradients** problem.\n",
    "    - The hyperparameter α defines the value that the ELU function approaches when z is a large negative number.\n",
    "    - It is usually set to 1, but you can tweak it like any other hyperparameter.\n",
    "\n",
    "\n",
    "- It has a nonzero gradient for z < 0, which avoids the **dead neurons** problem.\n",
    "\n",
    "\n",
    "- If α is equal to 1 then the function is smooth everywhere, including around z = 0, which helps speed up Gradient Descent since it does not bounce as much to the left and right of z = 0.\n",
    "\n",
    "\n",
    "- The main drawback of the ELU activation function is that it is slower to compute than the ReLU function and its variants (due to the use of the exponential function).\n",
    "\n",
    "\n",
    "- Its faster convergence rate during training compensates for that slow computation, but still, at test time an ELU network will be slower than a ReLU network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>SELU</center></h1>\n",
    "\n",
    "- SELU is a scaled variant of the ELU activation function.\n",
    "\n",
    "\n",
    "- The authors showed that if you build a neural network composed exclusively of a stack of dense layers, and if all hidden layers use the SELU activation function, then the network will self-normalize: the output of each layer will tend to preserve a mean of 0 and standard deviation of 1 during training, which solves the **vanishing/exploding gradients** problem.\n",
    "\n",
    "\n",
    "- As a result, the SELU activation function often significantly outperforms other activation functions for such neural nets (especially deep ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, 5, -2.2, 3.2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)\n",
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>SELU Conditions</center></h1>\n",
    "\n",
    "- There are a few conditions for self-normalization of SELU to happen:\n",
    "    - The input features must be standardized (mean 0 and standard deviation 1).\n",
    "    \n",
    "    - Every hidden layer’s weights must be initialized with LeCun normal initialization. In Keras, this means setting `kernel_initializer=\"lecun_normal\"`.\n",
    "    \n",
    "    - The network’s architecture must be sequential.\n",
    "    \n",
    "    - If you try to use SELU in nonsequential architectures, such as RNNs or networks with skip connections (i.e., connections that skip layers, such as in Wide & Deep nets), self-normalization will not be guaranteed, so SELU will not necessarily outperform other activation functions.\n",
    "    \n",
    "    - The paper only guarantees self-normalization if all layers are dense, but some researchers have noted that the SELU activation function can improve performance in Convolutional Neural Nets (CNNs) as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Batch Normalization</center></h1>\n",
    "\n",
    "- There is yet another technique to address **vanishing/exploding gradients** problems.\n",
    "\n",
    "\n",
    "- The **Batch Normalization (BN)** technique consists of adding an operation in the model just before or after the activation function of each hidden layer.\n",
    "\n",
    "\n",
    "- This operation simply zero-centers and normalizes each input, then scales and shifts the result using two new parameter vectors per layer: one for scaling, the other for shifting. In other words, the operation lets the model learn the optimal scale and mean of each of the layer’s inputs.\n",
    "\n",
    "\n",
    "- So during training, BN standardizes its inputs, then rescales and offsets them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Equation 11-3: Batch Normalization algorithm** - Optional Reading from textbook\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "1.\\quad & \\mathbf{\\mu}_B = \\dfrac{1}{m_B}\\sum\\limits_{i=1}^{m_B}{\\mathbf{x}^{(i)}}\\\\\n",
    "2.\\quad & {\\mathbf{\\sigma}_B}^2 = \\dfrac{1}{m_B}\\sum\\limits_{i=1}^{m_B}{(\\mathbf{x}^{(i)} - \\mathbf{\\mu}_B)^2}\\\\\n",
    "3.\\quad & \\hat{\\mathbf{x}}^{(i)} = \\dfrac{\\mathbf{x}^{(i)} - \\mathbf{\\mu}_B}{\\sqrt{{\\mathbf{\\sigma}_B}^2 + \\epsilon}}\\\\\n",
    "4.\\quad & \\mathbf{z}^{(i)} = \\gamma \\hat{\\mathbf{x}}^{(i)} + \\beta\n",
    "\\end{split}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The authors of the BN paper argued in favor of adding the BN layers before the activation functions,\n",
    "# rather than after.\n",
    "# There is some debate about this, as which is preferable seems to depend on the task,\n",
    "# so you can experiment with this too to see which option works best on your dataset.\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Gradient Clipping</center></h1>\n",
    "\n",
    "- Another popular technique to mitigate the **exploding gradients** problem is to clip the gradients during backpropagation so that they never exceed some threshold. This is called Gradient Clipping.\n",
    "\n",
    "\n",
    "- This technique is most often used in recurrent neural networks RNNs, as **Batch Normalization** is tricky to use in RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Gradient Clipping</center></h1>\n",
    "\n",
    "<center><img src=\"img/gradient-clipping.png\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# All Keras optimizers accept clipnorm or clipvalue arguments:\n",
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Transfer Learning</center></h1>\n",
    "\n",
    "- It is generally not a good idea to train a very large DNN from scratch: instead, you should always try to find an existing neural network that accomplishes a similar task to the one you are trying to tackle, then reuse the lower layers of this network. This technique is called **transfer learning**.\n",
    "\n",
    "- It will not only speed up training considerably, but also require significantly less training data.\n",
    "\n",
    "<center><img src=\"img/transfer-learning.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Image from Ref[1]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Unsupervised Pretraining</center></h1>\n",
    "\n",
    "- Suppose you want to tackle a complex task for which you don’t have much labeled training data, but unfortunately you cannot find a model trained on a similar task.\n",
    "\n",
    "\n",
    "- If you can gather plenty of unlabeled training data, you can try to use it to train an unsupervised model, such as an autoencoder or a Generative Adversarial Network (GAN).\n",
    "\n",
    "\n",
    "- Then you can reuse the lower layers of the autoencoder or the lower layers of the GAN’s discriminator, add the output layer for your task on top, and fine- tune the final network using supervised learning (i.e., with the labeled training examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Unsupervised Pretraining</center></h1>\n",
    "\n",
    "<center><img src=\"img/unsupervised-pretraining.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Image from Ref[1]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Momentum Optimization</center></h1>\n",
    "\n",
    "- Imagine a bowling ball rolling down a gentle slope on a smooth surface: it will start out slowly, but it will quickly pick up momentum until it eventually reaches terminal velocity (if there is some friction or air resistance).\n",
    "\n",
    "\n",
    "- This is the very simple idea behind **momentum optimization**, proposed by Boris Polyak in 1964.\n",
    "\n",
    "\n",
    "- In contrast, regular Gradient Descent will simply take small, regular steps down the slope, so the algorithm will take much more time to reach the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Momentum Optimization Cont.</center></h1>\n",
    "\n",
    "- Momentum optimization cares a great deal about what previous gradients were: at each iteration, it subtracts the local gradient from the momentum vector m (multiplied by the learning rate η), and it updates the weights by adding this momentum vector (see Equation 11-4).\n",
    "\n",
    "\n",
    "- In other words, the gradient is used for acceleration, not for speed. To simulate some sort of friction mechanism and prevent the momentum from growing too large, the algorithm introduces a new hyperparameter β, called the momentum, which must be set between 0 (high friction) and 1 (no friction). A typical momentum value is 0.9.\n",
    "\n",
    "**Equation 11-4: Momentum algorithm**\n",
    "\n",
    "1. $\\mathbf{m} \\gets \\beta \\mathbf{m} - \\eta \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta})$\n",
    "2. $\\boldsymbol{\\theta} \\gets \\boldsymbol{\\theta} + \\mathbf{m}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Momentum Optimization</center></h1>\n",
    "\n",
    "<center><img src=\"img/momentum.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Image from Ref[1]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>AdaGrad</center></h1>\n",
    "\n",
    "<center><img src=\"img/adagrad.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Image from Ref[1]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Optimizers Summary</center></h1>\n",
    "\n",
    "<center><img src=\"img/optimizer-table.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Image from Ref[1]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Optimizers Demo</center></h1>\n",
    "\n",
    "https://www.deeplearning.ai/ai-notes/optimization/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Learning Rate Scheduling</center></h1>\n",
    "\n",
    "- See different scheduling techniques (power scheduling, exponential scheduling, 1cycle scheduling, etc.) in [Ch-11 notebook](https://github.com/ageron/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb).\n",
    "\n",
    "<center><img src=\"img/learning-rate.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Image from Ref[1]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Regularization</center></h1>\n",
    "\n",
    "- Deep neural networks typically have tens of thousands of parameters, sometimes even millions. This gives them an incredible amount of freedom and means they can fit a huge variety of complex datasets.\n",
    "\n",
    "\n",
    "- However, this great flexibility also makes the network prone to **overfitting** the training set. **Regularization** is required to avoid **overfitting**.\n",
    "\n",
    "\n",
    "- We already implemented one of the best regularization techniques: **early stopping**.\n",
    "\n",
    "\n",
    "- Moreover, even though **Batch Normalization** was designed to solve the unstable gradients problems, it also acts like a pretty good regularizer.\n",
    "\n",
    "\n",
    "- Just like regularization can be applied for simple linear models, you can use l2 regularization to constrain a neural network’s connection weights, and/or l1 regularization if you want a sparse model (with many weights equal to 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Regularization\n",
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
    "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Dropout</center></h1>\n",
    "\n",
    "<center><img src=\"img/dropout.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Image from Ref[1]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h1><center>Coming Up Next: Convolutional Neural Networks</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<h1><center>References</center></h1>\n",
    "\n",
    "[1] Hands-On ML Textbook Edition-2 2019"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
